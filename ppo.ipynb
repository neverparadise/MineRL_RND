{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\gym\\logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "import minerl\n",
    "import gym\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.framestack import FrameBuffer\n",
    "from wrapper.preprocess import PreprocessAtari\n",
    "\n",
    "def make_env():\n",
    "    env = gym.make(\"MineRLTreechop-v0\")\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_11action(self, env, action_index):\n",
    "    # Action들을 정의\n",
    "    action = env.action_space.noop()\n",
    "    # Cameras\n",
    "    if (action_index == 0):\n",
    "        action['camera'] = [0, 0]\n",
    "    elif (action_index == 1):\n",
    "        action['camera'] = [0, -5]\n",
    "    elif (action_index == 2):\n",
    "        action['camera'] = [0, 5]\n",
    "    elif (action_index == 3):\n",
    "        action['camera'] = [-5, 0]\n",
    "    elif (action_index == 4):\n",
    "        action['camera'] = [5, 0]\n",
    "\n",
    "    # Forwards\n",
    "    elif (action_index == 5):\n",
    "        action['forward'] = 0\n",
    "    elif (action_index == 6):\n",
    "        action['forward'] = 1\n",
    "\n",
    "    # Jump\n",
    "    elif (action_index == 7):\n",
    "        action['jump'] = 0\n",
    "    elif (action_index == 8):\n",
    "        action['jump'] = 1\n",
    "\n",
    "    # Attack \n",
    "    elif (action_index == 9):\n",
    "        action['attack'] = 0\n",
    "    elif (action_index == 10):\n",
    "        action['attack'] = 1\n",
    "\n",
    "def save_model(self, model):\n",
    "        torch.save({'model_state_dict': model.state_dict()}, './PPO.pth')\n",
    "        print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(observation):\n",
    "    obs = observation['pov']\n",
    "    obs = obs / 255.0\n",
    "    obs = torch.from_numpy(obs)\n",
    "    obs = obs.permute(2, 0, 1)\n",
    "    return obs.float().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "learning_rate = 0.0005\n",
    "gamma         = 0.98\n",
    "lmbda         = 0.95\n",
    "eps_clip      = 0.1\n",
    "K_epoch       = 3\n",
    "T_horizon     = 20\n",
    "\n",
    "class PPO(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super(PPO, self).__init__()\n",
    "        self.num_actions = num_actions\n",
    "        self.data = []\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "        nn.Conv2d(4, 32, kernel_size=8, stride=4),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        def conv2d_size_out(size, kernel_size=3, stride=2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "\n",
    "        conv_size = conv2d_size_out(64, 8, 4)\n",
    "        conv_size = conv2d_size_out(conv_size, 4, 2)\n",
    "        conv_size = conv2d_size_out(conv_size, 3, 1)\n",
    "        linear_input_size = conv_size * conv_size * 64 # 4 x 4 x 64 = 1024\n",
    "\n",
    "        self.fc_pi = nn.Linear(linear_input_size, self.num_actions)\n",
    "        self.fc_v = nn.Linear(linear_input_size, 1)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def pi(self, x, softmax_dim=0):\n",
    "        if len(x.shape) < 4:\n",
    "          x = x.unsqueeze(0)\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_pi(x)\n",
    "        prob = F.softmax(x, dim=softmax_dim)\n",
    "        return prob\n",
    "    \n",
    "    def v(self, x):\n",
    "        if len(x.shape) < 4:\n",
    "          x = x.unsqueeze(0)\n",
    "        x = self.conv_layers(x)\n",
    "        v = self.fc_v(x)\n",
    "        return v\n",
    "      \n",
    "    def put_data(self, transition):\n",
    "        self.data.append(transition)\n",
    "        \n",
    "    def make_batch(self):\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, prob_a_lst, done_lst = [], [], [], [], [], []\n",
    "        for transition in self.data:\n",
    "            s, a, r, s_prime, prob_a, done = transition\n",
    "            \n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            prob_a_lst.append([prob_a])\n",
    "            done_mask = 0 if done else 1\n",
    "            done_lst.append([done_mask])\n",
    "            \n",
    "        s,a,r,s_prime,done_mask, prob_a = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "                                          torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "                                          torch.tensor(done_lst, dtype=torch.float), torch.tensor(prob_a_lst)\n",
    "        self.data = []\n",
    "        return s, a, r, s_prime, done_mask, prob_a\n",
    "        \n",
    "    def train_net(self):\n",
    "        s, a, r, s_prime, done_mask, prob_a = self.make_batch()\n",
    "\n",
    "        for i in range(K_epoch):\n",
    "            td_target = r + gamma * self.v(s_prime) * done_mask\n",
    "            delta = td_target - self.v(s)\n",
    "            delta = delta.detach().numpy()\n",
    "\n",
    "            advantage_lst = []\n",
    "            advantage = 0.0\n",
    "            for delta_t in delta[::-1]:\n",
    "                advantage = gamma * lmbda * advantage + delta_t[0]\n",
    "                advantage_lst.append([advantage])\n",
    "            advantage_lst.reverse()\n",
    "            advantage = torch.tensor(advantage_lst, dtype=torch.float)\n",
    "\n",
    "            pi = self.pi(s, softmax_dim=1)\n",
    "            pi_a = pi.gather(1,a)\n",
    "            ratio = torch.exp(torch.log(pi_a) - torch.log(prob_a))  # a/b == exp(log(a)-log(b))\n",
    "\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantage\n",
    "            loss = -torch.min(surr1, surr2) + F.smooth_l1_loss(self.v(s) , td_target.detach())\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4, 1])\n",
      "tensor([[ 0.0705, -2.2701, -0.7842,  1.2794, -0.1607,  0.2796],\n",
      "        [-0.8574,  0.6490, -1.6332,  0.5814, -1.5433,  0.2243],\n",
      "        [ 1.6867,  0.5200,  2.3955,  0.2559, -0.3255,  0.1514],\n",
      "        [ 0.3080, -2.0061, -0.9902, -1.2209, -0.3632,  1.3364]])\n",
      "tensor([[ 1.2522, -3.5641, -1.2512,  0.1079, -2.2517,  2.3826]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttentionScore(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(AttentionScore, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 256)\n",
    "        self.W = nn.Linear(hidden_dim, 256, bias=False)\n",
    "        self.Z = 1.0\n",
    "        self.linear2 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, v, h):\n",
    "        x = F.tanh(self.linear1(v) + self.W(h))\n",
    "        out = torch.exp((self.linear2(x)))/ self.Z\n",
    "        return out\n",
    "\n",
    "class SoftAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SoftAttention, self).__init__()\n",
    "        self.attention_score = AttentionScore(input_dim, hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, v, h):\n",
    "        print(v.shape)\n",
    "        print(h.shape)\n",
    "        scores = self.attention_score(v, h)\n",
    "        print(scores.shape)\n",
    "        z = torch.matmul(v.T, scores)\n",
    "        return z.T\n",
    "\n",
    "v = torch.randn(4, 6)\n",
    "h = torch.randn(4, 8)\n",
    "softattention = SoftAttention(6, 8, 1)\n",
    "context = softattention(v, h)\n",
    "print(v)\n",
    "print(context)\n",
    "print(context.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UnicodeDecodeError, switching to default encoding\n",
      "Exception in thread Thread-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\minerl\\env\\malmo.py\", line 562, in log_to_file\n",
      "    linestr = line.decode(mine_log_encoding)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa1 in position 51: invalid start byte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\minerl\\env\\malmo.py\", line 566, in log_to_file\n",
      "    linestr = line.decode(mine_log_encoding)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa1 in position 51: invalid start byte\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 4, 8, 8], expected input[1, 3, 64, 64] to have 4 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_49404\\2878214737.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_horizon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_49404\\3048798711.py\u001b[0m in \u001b[0;36mpi\u001b[1;34m(self, x, softmax_dim)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m           \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_pi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoftmax_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ye200\\anaconda3\\envs\\minerl\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 443\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 4, 8, 8], expected input[1, 3, 64, 64] to have 4 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "total_episodes = 10\n",
    "print_interval = 20\n",
    "env = gym.make(\"MineRLTreechop-v0\")\n",
    "model = PPO(num_actions=11)\n",
    "\n",
    "\n",
    "for n_epi in range(total_episodes):\n",
    "    score = 0.0\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        for t in range(T_horizon):\n",
    "            prob = model.pi(converter(s))\n",
    "            m = Categorical(prob)\n",
    "            a = m.sample().item()\n",
    "            action = make_11action(env, a)\n",
    "            s_prime, r, done, info = env.step(action)\n",
    "\n",
    "            model.put_data((s, a, r, s_prime, prob[a].item(), done))\n",
    "            s = s_prime\n",
    "            score += r\n",
    "            if done:\n",
    "                print(\"# of episode :{}, score : {:.1f}\".format(n_epi, score))\n",
    "                break\n",
    "\n",
    "        model.train_net()\n",
    "\n",
    "    if n_epi%print_interval==0 and n_epi!=0:\n",
    "        print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, score/print_interval))\n",
    "        score = 0.0\n",
    "\n",
    "env.close()\n",
    "\n",
    "save_model(model)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "266dbc1b53b3a75132c42213de358c469c42e7e8486df6091cb08cba7b9be0d5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('minerl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
